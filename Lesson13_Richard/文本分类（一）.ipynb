{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法【引用自[百度百科](https://baike.baidu.com/item/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/365730?fr=aladdin)】。它是一种交叉学科，融合了计算机学、语言学、统计学、数学等学科知识。近年来随着机器学习技术的发展，自然语言处理模型也取得了一系列的进展，特别是在在语音文字转换、机器翻译、情感分析、文本分类等方向有了突破性的工作。\n",
    "\n",
    "文本分类是自然语言处理，也可以说是信息检索里面的一部分。通过分析文本的标题、标签、内容等信息，确定文本的类别。比如垃圾邮件识别就是一种文本分类，利用模型分析邮件内容以区分正常邮件和垃圾邮件；还有新闻分类，根据新闻所谈论的内容，分为政治、经济、体育等类。建立高效准确的文本自动分类系统，能够有效管理各类文档，滤除无关信息以提升工作效益。\n",
    "\n",
    "文本分类里面有三个重要的步骤：\n",
    "- 1.文本清洗。去除与文本主要意思无关的符号、空格、空行，对文本进行分词。\n",
    "- 2.文本表达。文本中提取特征，将文本符号转换成具有数学意义的矩阵、向量等表达方式，以作为分类算法的输入。\n",
    "- 3.分类。采用监督学习方法，训练样本数据建立分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面结合电影评论数据分类案例来讲解文本分类的这三个流程实施过程。但是之前需要对文本数据特点进行分析，以对应设计预处理方法和分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.文本特点分析\n",
    "电影评论数据可以直接通过nltk工具包直接获取，里面可以读取每篇评论内容、感情色彩以及单词。部分代码参考了CSDN博客http://blog.csdn.net/sinat_20791575/article/details/58661827 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = movie_reviews.categories()\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "电影评论从感情色彩上分为积极与负面两种类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数量： 2000\n"
     ]
    }
   ],
   "source": [
    "print('评论数量：', len(movie_reviews.fileids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "积极评论数量： 1000\n",
      "负面评论数量： 1000\n"
     ]
    }
   ],
   "source": [
    "print('积极评论数量：', len(movie_reviews.fileids('pos')))\n",
    "print('负面评论数量：', len(movie_reviews.fileids('neg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两种类型的数据是均衡的。下面我们查看第一个文件数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\none of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \\nwhat\\'s the deal ? \\nwatch the movie and \" sorta \" find out . . . \\ncritique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \\nwhich i'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = movie_reviews.fileids()[0]\n",
    "movie_reviews.open(first).read()[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到当前文档除了单词之外还有标点符号，数字换行符等。在后面的处理中，我们可以将这些标点符号看成是没有意义的去除掉，也可以保留下来作为一个符号进行分析，特别是问号、感叹号也包含一定感情色彩。\n",
    "\n",
    "**注意，一般读取的文档内容都是句子或者段落的长文本，需要进行分词。**\n",
    "\n",
    "这里我们保留所有的符号，下面我们通过nltk工具获取每篇文章的单词以及对应的情感标签。nltk已经对文本进行了分词，但是为了演示完整流程，我们使用原始的文本，将原始的长文本分成单词和标点符号序列；分词时还可以分成2元组、3元组(n-gram)，比如“machine learning\"、“a good dog”。对于中文稍微有些复杂，因为没有空格来区分词组，比如“今天我买了一件衣服”，每个汉字可以当做一个词，但是根据常识应该分为“今天”、“我”、“买了”、“一件”、“衣服”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取每篇评论及其对应的标签\n",
    "document_label_pairs = [(movie_reviews.raw(fileid), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#随机打乱次序\n",
    "np.random.shuffle(document_label_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents, labels = list(zip(*document_label_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.文本清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本清洗可以看成是数据预处理。一般有两项工作：\n",
    "- 去除无意义符号。文本一般还有文字、标点符号、空格、数字，甚至有很多缩写、外文、错误的拼写，有的时候我们只需要处理单纯的文本比如单词或汉字，其他符号可以当做噪声去除掉。\n",
    "- 对文本进行分词。将文本内容分成词组等形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面我们已经利用nltk工具直接获得了每篇评论的单词序列，这里再自己做一遍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果原始文件是一个字符串，比如我们将上文看作一个长字符串，并且需要去掉标点符号，我们可以使用Python工具完成。\n",
    "\n",
    "### 2.1文本清洗示例\n",
    "可以正则表达式来去掉标点符号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shakespeare in love is quite possibly the most enjoyable period piece ever made for the silver screen  \\nit is both humorous and romantic in a very unique blend that can successfully entertain any audience for the nearly 2 and and a half hours that it occupies  \\nthat is  however  not to say it is a good film  a quality production or anything of the sort  \\nshakespeare in love is an incredibly cheap '"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#正则表达，去除表达符号\n",
    "import re\n",
    "text = document_label_pairs[0][0]\n",
    "#指定需要去掉的标点符号\n",
    "text = re.sub('[,.!:;#()-]', '', text)\n",
    "text[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shakespeare', 'in', 'love', 'is', 'quite', 'possibly', 'the', 'most', 'enjoyable', 'period', 'piece', 'ever', 'made', 'for', 'the', 'silver', 'screen', 'it', 'is', 'both']\n"
     ]
    }
   ],
   "source": [
    "#分词\n",
    "print(text.split()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2对电影评论数据进行文本清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#去掉标点符号\n",
    "documents = [re.sub('[_,.!:;#()0-9]', '', text) for text in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#英文单词分词\n",
    "document_words = [text.split() for text in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#统计单词频率\n",
    "total_words = []\n",
    "import itertools\n",
    "total_words = list(itertools.chain.from_iterable(document_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1315218"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#总共的单词频率\n",
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49856"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#统计每个单词的频率\n",
    "from collections import Counter\n",
    "word_freq_dict = Counter(total_words)\n",
    "len(word_freq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看看“dog”这个单词的频率，并对高频率单词进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_dict['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "words, freqs = list(word_freq_dict.keys()), list(word_freq_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_word_pair = list(zip(freqs, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#按照词频从高到低排序\n",
    "freq_word_pair.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 20 artists>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAHWCAYAAADdDkViAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121dd5570b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(figsize=(10,8))\n",
    "top_20 = freq_word_pair[:20]\n",
    "freq20, words20 = list(zip(*top_20))\n",
    "pyplot.bar(left=range(20), tick_label=words20, height=freq20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1LP/X+qJzo7onJAmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121d094feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_len = [len(doc) for doc in documents]\n",
    "_ = pyplot.hist(document_len, bins=15)\n",
    "_ = pyplot.title('Document Lengths Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分布图有些偏态。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3训练集和测试集划分\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "doc_train, doc_test, label_train, label_test = train_test_split(documents, labels, test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.文本表达\n",
    "\n",
    "文本数据特点是字符多、长度不一致，提取特征比一般的数据复杂。文本表达大致有三个方向，具体可参考[CSDN博客](http://blog.csdn.net/wangongxi/article/details/51591031)：\n",
    "- 传统上的模型有词袋模型，也就是将文本看成单词的集合，不考虑单词的次序，比如\"I love this dog\"可以表达成[I, love, this, dog]，但是这样依然是文字符号，人能理解，计算机不能理解，所以需要转换成向量等形式以作为计算机的输入，比如将句子表示成词库中每个单词的频率组成的向量。通常文本库中的单词量很大，数万、数十万，很多单词只在部分文本中出现，所以文本表示的矩阵是维数很高的稀疏矩阵。\n",
    "- 90年代有学者提出了[主题模型](http://blog.csdn.net/huagong_adu/article/details/7937616)，也就是将文档看成是若干主题的组合，比如一篇文章既讨论政治又讨论经济，而主题又是单词的组合。比较主流的有LSA方法，LDA方法等。\n",
    "![Topic Model](http://img.my.csdn.net/uploads/201209/03/1346651772_3109.PNG)\n",
    "- 近年来，随着深度学习的雄起，词嵌入（word embedding), 句子嵌入（sentence embedding）等概念和方法在文本处理中取得了突飞猛进。其理念是使用嵌入低维向量来表示单词、句子甚至文档，意义相近的单词距离较近，同理，意义相近的句子或文档向量距离也比较近。\n",
    "\n",
    "**本次主要讨论词袋模型**。\n",
    "\n",
    "词袋模型首先要建立一个单词库，一般是文档中所有单词的交集。词袋模型的表示有如下方法：\n",
    "### 3.1单词是否出现在文档中\n",
    "将所有文本单词（或词组）进行统计，建立所有文档单词库和频率字典，每篇文档可以表示为单词库中单词0，1值所组成的向量，1表示该单词在文档中存在，0表示不存在。比如：\n",
    "\n",
    "\n",
    "s1 = 'I like dogs very very much.', s2 = 'He likes dogs too.' 单词库vocab=[I, like, he, likes, dogs, too, very, much]，那么\n",
    "s1可以表示成向量[1, 1, 0, 0, 1, 0]，如下表："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "| 句子 | I | like | he | likes | dogs | too| very | much\n",
    "| - | :-: |  -: |  -: | -: |-: |-: |-: |-: |\n",
    "| S1 | 1 | 1 | 0 | 0 | 1 | 0 | 1 | 1|\n",
    "|S2 | 0 | 0 | 1 | 1 | 1 | 1 | 0 | 0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以直接使用sklearn中的CountVectorizer来建立词库并计算每个句子的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This is the second second document.',\n",
    "     'And the third one.',\n",
    "     'Is this the first document?',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(corpus)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 0,\n",
       " 'document': 1,\n",
       " 'first': 2,\n",
       " 'is': 3,\n",
       " 'one': 4,\n",
       " 'second': 5,\n",
       " 'the': 6,\n",
       " 'third': 7,\n",
       " 'this': 8}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2单词频率值 \n",
    "除了0，1值之外，句子还可以使用单词库中单词频率值表示向量。\n",
    "\n",
    "\n",
    "| 句子 | I | like | he | likes | dogs | too| very | much\n",
    "| - | :-: |  -: |  -: | -: |-: |-: |-: |-: |\n",
    "| S1 | 1 | 1 | 0 | 0 | 1 | 0 | 2| 1|\n",
    "|S2 | 0 | 0 | 1 | 1 | 1 | 1 | 0 | 0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This is the second second document.',\n",
    "     'And the third one.',\n",
    "     'Is this the first document?',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词频向量中，出现频率比较高的单词影响比较大，比如在一篇文章中多次出现医学、医院等词组的话，该篇很容易被划分为医学类；但是还有一些词，比如冠词“the”、“a”还有动词“do”、“make”、“come”几乎在每篇文章中大量出现，可以说对分类没有意义，但是频率又非常高。\n",
    "\n",
    "### 3.3TFIDF表示方法\n",
    "为了解决高频率单词这个问题，学者又提出了\n",
    "TfIdf(term frequency, inversed document frequency)模型来表达文本，既考虑单词在某篇文章中的词频(term frequency)，又考虑该单词出现在所有文档上的频率(document frequency, 也就是出现该单词的文档数量)。TfIdf值计算公式如下：\n",
    "$$tf = \\frac {单词在当前文档中频率}{该文档中所有单词频率和}$$\n",
    "$$idf = log(\\frac {文档总数量}{出现该单词的文档数量})$$\n",
    "\n",
    "$$tfidf = tf*idf$$\n",
    "比如100篇文档，单词“make”在第一篇文档中出现的频率为10，有50篇文档里面有该单词，那么该文档中单词“make”的词频为10，单词总频数为680， document frequency=50。\n",
    "$$tfid = 10/680 * log(100/50)=0.0102$$\n",
    "当然，上述公式定义不唯一，具体可参考[Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)。\n",
    "\n",
    "无论是统计词频还是计算tfidf值，都可以利用Python来一步一步实现，但是sklearn工具包提供了TfIdfVectorizer工具，能够将长文本直接分词统计词频计算TfIdf值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This is the second second document.',\n",
    "     'And the third one.',\n",
    "     'Is this the first document?',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.43877674  0.54197657  0.43877674  0.          0.\n",
      "   0.35872874  0.          0.43877674]\n",
      " [ 0.          0.27230147  0.          0.27230147  0.          0.85322574\n",
      "   0.22262429  0.          0.27230147]\n",
      " [ 0.55280532  0.          0.          0.          0.55280532  0.\n",
      "   0.28847675  0.55280532  0.        ]\n",
      " [ 0.          0.43877674  0.54197657  0.43877674  0.          0.\n",
      "   0.35872874  0.          0.43877674]]\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.4电影评论TfIdf特征提取\n",
    "利用sklearn工具包进行特征提取，去掉连接词，最低保留单词频率为2。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=2, stop_words='english', ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(doc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_train_vec = vectorizer.transform(doc_train)\n",
    "doc_test_vec = vectorizer.transform(doc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Shape: (1400, 19798)\n",
      "Testing data Shape: (600, 19798)\n"
     ]
    }
   ],
   "source": [
    "print('Training data Shape:', doc_train_vec.shape)\n",
    "print('Testing data Shape:', doc_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(doc_train_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aardman</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abby</th>\n",
       "      <th>...</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoologist</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorg</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaliyah  aardman  aaron  abandon  abandoned  abandoning  \\\n",
       "doc1  0.0      0.0      0.0    0.0      0.0        0.0         0.0   \n",
       "doc2  0.0      0.0      0.0    0.0      0.0        0.0         0.0   \n",
       "doc3  0.0      0.0      0.0    0.0      0.0        0.0         0.0   \n",
       "doc4  0.0      0.0      0.0    0.0      0.0        0.0         0.0   \n",
       "doc5  0.0      0.0      0.0    0.0      0.0        0.0         0.0   \n",
       "\n",
       "      abandonment  abandons  abby  ...    zoo  zoologist  zoom  zooming  \\\n",
       "doc1          0.0       0.0   0.0  ...    0.0        0.0   0.0      0.0   \n",
       "doc2          0.0       0.0   0.0  ...    0.0        0.0   0.0      0.0   \n",
       "doc3          0.0       0.0   0.0  ...    0.0        0.0   0.0      0.0   \n",
       "doc4          0.0       0.0   0.0  ...    0.0        0.0   0.0      0.0   \n",
       "doc5          0.0       0.0   0.0  ...    0.0        0.0   0.0      0.0   \n",
       "\n",
       "      zooms  zorg  zorro  zucker  zuko  zwick  \n",
       "doc1    0.0   0.0    0.0     0.0   0.0    0.0  \n",
       "doc2    0.0   0.0    0.0     0.0   0.0    0.0  \n",
       "doc3    0.0   0.0    0.0     0.0   0.0    0.0  \n",
       "doc4    0.0   0.0    0.0     0.0   0.0    0.0  \n",
       "doc5    0.0   0.0    0.0     0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 19798 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = vectorizer.get_feature_names()\n",
    "data.index = ['doc'+str(i+1) for i in range(len(data))]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是个很庞大的稀疏矩阵，所以sklearn将之存储到稀疏矩阵里。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.分类\n",
    "\n",
    "这是一个监督学习里面的二元分类问题，分类的方法可以采用传统的统计机器学习方法比如决策树、朴素贝叶斯、逻辑回归、提升树等；也可以使用多层神经网络。\n",
    "\n",
    "### 4.1朴素贝叶斯\n",
    "我们首先使用经典的朴素贝叶斯方法进行分类，假设单词的条件概率都是独立的，计算每个类别单词出现的条件概率，每个文本的条件概率就是每个单词的条件概率之积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(clf):\n",
    "    start = time.time()\n",
    "    #训练\n",
    "    clf.fit(doc_train_vec, label_train)\n",
    "    end = time.time()\n",
    "    print('训练时间：{:.3f}'.format(end-start))\n",
    "    #预测\n",
    "    preds = clf.predict(doc_test_vec)\n",
    "    #计算准准确率\n",
    "    #Micro F1\n",
    "    print('Micro F1: {:.3f}'.format(f1_score(label_test, preds, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：0.005\n",
      "Micro F1: 0.825\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "train_test(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看看，哪些标签为'pos'类别文章中哪些特征单词的条件概率大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n",
      "['film', 'movie', 'like', 'just', 'bad', 'good', 'time', 'plot', 'story', 'action', 'character', 'characters', 'really', 'make', 'don', 'big', 'little', 'doesn', 'scene', 'films']\n",
      "pos\n",
      "['film', 'movie', 'like', 'story', 'life', 'good', 'just', 'time', 'character', 'films', 'characters', 'way', 'does', 'best', 'man', 'great', 'people', 'new', 'love', 'really']\n"
     ]
    }
   ],
   "source": [
    "for l in range(2):\n",
    "    print(clf.classes_[l])\n",
    "    con_prob1 = clf.feature_log_prob_[l, :]\n",
    "    top_k = con_prob1.argsort()[-20:][::-1]\n",
    "    temp_words = []\n",
    "    for i in top_k:\n",
    "        temp_words.append(vectorizer.get_feature_names()[i])\n",
    "    \n",
    "    print(temp_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到负面评价中有Bad， don't， doesn't等单词，而正面评价中有good, best, great, love等单词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 集成方法\n",
    "还可以尝试集成方法，三个臭皮匠赛过诸葛亮。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：0.376\n",
      "Micro F1: 0.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "#clf_ad = AdaBoostClassifier(n_estimators=100, learning_rate=2).fit(X_train_tfidf, y_train)\n",
    "clf_rf = RandomForestClassifier(n_estimators=50, n_jobs=4)\n",
    "clf_ada = AdaBoostClassifier()\n",
    "train_test(clf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：1.905\n",
      "Micro F1: 0.760\n"
     ]
    }
   ],
   "source": [
    "train_test(clf_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用默认参数的继承方法效果并不明显。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3多层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间：29.318\n",
      "Micro F1: 0.862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(80,20), max_iter=300, alpha=1e-4,\n",
    "                    solver='sgd', verbose=False, tol=5e-5, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "train_test(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络的效果要好于前面提到的模型，但是训练耗费时间较多。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
